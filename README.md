## 入门

https://github.com/EssayKillerBrain/EssayKiller_V2  看看大牛操作，无需考虑代码。tf1,gpt2预训练模-文章生成

https://github.com/mymusise/gpt2-quickly    tf2 + hugging face 简洁明了的使用示范，高度封装的框架，了解原理

# 新人建议直接在hugging face封装的训练框架的基础上开始学习，避免淹没在网上各式各样的写法中，心力憔悴。
# 本人php开发，转型开始学习nlp，我认为这是最快速能够得到成效的途径。也借此能够做出产品。（2个月从0到1）
# 但是熟悉框架用法之后，应当回过头再去学习参数，框架，甚至算法的原理。这是必须的。这就可以避免出去面试的时候，当有人问起你php的laravel框架，甚至php内置函数sort排序算法的c语言是怎么做的，回答不上来的尴尬。

tf1版本gpt2的一种预训练模型
https://github.com/wind91725/gpt2-ml-finetune-/issues/10

清华关于nlp研究的官网
https://cpm.baai.ac.cn/
tf版本gpt2预训练模型，转化清华开源的模型用
https://github.com/bojone/CDial-GPT-tf

pytorch中文摘要生成
https://github.com/qingkongzhiqian/GPT2-Summary

国内框架1
https://github.com/bojone/bert4keras

国内框架2
https://github.com/BrikerMan/Kashgari

框架作者的博客
https://kexue.fm/archives/7867

国外对于gpt2使用的介绍
https://github.com/minimaxir/gpt-2-simple


## 应用

训练平台
https://openbayes.com/pricing/
colab
https://colab.research.google.com/ google提供的免费平台，gpu/tpu（随机分发，都是好配置，远超国内各大平台提供的免费环境。只是要fan qiang）

## 学习：
https://github.com/apachecn/AiLearning  还没看

## 有用的操作：
https://github.com/850886470/CPM-TF2Transformer  把gpt2中文模型转hugging face
